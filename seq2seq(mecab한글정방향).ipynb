{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq(mecab한글정방향).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Changyoon-Lee/realization_seq2seq/blob/master/seq2seq(mecab%ED%95%9C%EA%B8%80%EC%A0%95%EB%B0%A9%ED%96%A5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K30P_fc6q4j-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34ca220b-2556-43d3-a1de-f579877e9b08"
      },
      "source": [
        "!sudo apt-get install python3-dev; pip3 install konlpy   # Python 3.x\n",
        "!sudo apt-get install curl\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 71.8MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.7MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, tweepy, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.58.0-2ubuntu3.9).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Installing automake (A dependency for mecab-ko)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:5 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,857 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,041 kB]\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [896 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,558 B]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [885 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,338 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [27.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,417 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [116 kB]\n",
            "Ign:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [255 kB]\n",
            "Fetched 8,114 kB in 1s (5,748 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  autoconf autotools-dev libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev libsigsegv2 m4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 1,082 kB of archives.\n",
            "After this operation, 3,994 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Fetched 1,082 kB in 0s (10.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1381k  100 1381k    0     0  1027k      0  0:00:01  0:00:01 --:--:-- 6723k\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  17.6M      0  0:00:02  0:00:02 --:--:-- 22.3M\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./NR.csv ... 482\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./VX.csv ... 125\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./NP.csv ... 342\n",
            "reading ./MM.csv ... 453\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./J.csv ... 416\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./EP.csv ... 51\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./NNB.csv ... 140\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "remote: Counting objects: 17, done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 3), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Processing /tmp/mecab-python-0.996\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp36-cp36m-linux_x86_64.whl size=140567 sha256=ea58e73a267779ecc3c5cf11a6beef8dbbfe1a5afcfc14360e87e3c59c4f798e\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/75/a6/e9e73a1dbd73579383644942ef18a6d17ad728a3052a1147fb\n",
            "Successfully built mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv-nGWB3aeXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "cd7c2a30-534c-4919-a5f8-5a430aed54b7"
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5cNaBHybT0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "news_df = pd.read_excel('/gdrive/My Drive/강의자료/kor.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "train_df, val_df, test_df = news_df.iloc[:50000, 1:], news_df.iloc[50000:63000, 1:], news_df.iloc[63000:, 1:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXus8NdNb73Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5fdc9901-b025-4b79-8937-3f93459651d6"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def preprocess_sentences_eng(sentences):\n",
        "    sentence = []\n",
        "    for line in sentences:\n",
        "        tokens = word_tokenize(line)\n",
        "        tokens.insert(0,'<start>')\n",
        "        tokens.append('<end>')\n",
        "        sentence.append(' '.join(tokens))\n",
        "    return sentence\n",
        "def preprocess_sentences_kor(sentences):\n",
        "    mecab = Mecab()\n",
        "    sentence = []\n",
        "    for line in sentences:\n",
        "        tokens = mecab.morphs(line)\n",
        "        tokens.insert(0,'<end>')\n",
        "        tokens.append('<start>')\n",
        "        sentence.append(' '.join(tokens[::-1]))\n",
        "    return sentence\n",
        "\n",
        "def backprocess_sentence(sentence):\n",
        "    tokens = sentence.split()\n",
        "    tokens = tokens[1:-1]\n",
        "    return ' '.join(tokens)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sioFo_BLsKde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='', oov_token='oov')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBaRNUxqgs81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_en, test_en, val_en, train_kor, test_kor, val_kor = train_df['en'], test_df['en'], val_df['en'], train_df['ko'], test_df['ko'], val_df['ko']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVHKapVIvVle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_en = preprocess_sentences_eng(train_en)\n",
        "train_kor = preprocess_sentences_kor(train_kor)\n",
        "val_en = preprocess_sentences_eng(val_en)\n",
        "val_kor = preprocess_sentences_kor(val_kor)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwoQt-NAuIEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_set 들로 tokenizer에 fit 시킨다\n",
        "input_tensor_train, inp_lang = tokenize(train_kor)\n",
        "target_tensor_train, targ_lang = tokenize(train_en)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIKfzXNfwChu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c3bf9122-bdf9-4838-a2d0-2a09f5ffbe99"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor_train.shape[1], input_tensor_train.shape[1]\n",
        "print('kor vocab size : {}\\nen vocab size : {}'.format(len(inp_lang.word_index), len(targ_lang.word_index)))\n",
        "print('kor_sentence_maxlen : {}\\nen_sentence_maxlen : {}'.format(max_length_inp, max_length_targ))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kor vocab size : 17827\n",
            "en vocab size : 15640\n",
            "kor_sentence_maxlen : 32\n",
            "en_sentence_maxlen : 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQDndHCyh7Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_test(sent,lang='en'):\n",
        "    if lang=='ko':\n",
        "        tensor = inp_lang.texts_to_sequences(sent)\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen = max_length_inp,\n",
        "                                                         padding='post')\n",
        "        return tensor\n",
        "    else :\n",
        "        tensor = targ_lang.texts_to_sequences(sent)\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen =max_length_targ,\n",
        "                                                         padding='post')\n",
        "        return tensor"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q2EPlCJyQSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor_val = tokenize_test(val_kor, lang='ko')\n",
        "target_tensor_val = tokenize_test(val_en, lang='en')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoTj9yiTwUrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "50baefe0-2fd0-4ffd-ce2e-96c50cd4d1ff"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 ----> <start>\n",
            "5 ----> i\n",
            "47 ----> go\n",
            "7 ----> to\n",
            "6 ----> the\n",
            "6439 ----> attic\n",
            "225 ----> every\n",
            "584 ----> evening\n",
            "7 ----> to\n",
            "148 ----> meet\n",
            "8459 ----> bat\n",
            "4 ----> .\n",
            "3 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hAyyyRkxw9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "#validation set 나누기\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_thX5ObOxxfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cb33e7f-3118-4700-e8af-6e6f24f9c6d3"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        " "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 32]), TensorShape([64, 21]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDWD3W71xxdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.random.uniform(shape=(self.batch_sz, self.enc_units), minval=-0.08, maxval=0.08)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JlgiYGMzfXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3d0a7f9-b388-4e49-d649-c2559c71dff7"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 32, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM0sHV-1ze8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGu1Dh8Gzex-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1bec09f9-1c65-4a98-c435-94f03a82bae1"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ubfXA-zjGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA6xP2Xpzjjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f6806bf-f89b-4b6a-c622-8dc41f9eb930"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 15641)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo98Sj63zi-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oqP_veazp59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/gdrive/My Drive/강의자료/seq2seq_mecab(정방향)'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIgGAjpgzpw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "def test_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        " \n",
        "  enc_out, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47tpoLZEzsjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b86b4ca1-faf6-4ef2-d966-e7d1f43336e7"
      },
      "source": [
        "EPOCHS = 10\n",
        "loss_data = {'loss':[],'val_loss':[]}\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  for inp, targ in val_dataset.take(steps_per_epoch_val):\n",
        "    batch_val_loss = test_step(inp, targ, enc_hidden)\n",
        "    val_loss += batch_val_loss\n",
        "  \n",
        "\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  loss_data['loss'].append(total_loss / steps_per_epoch)\n",
        "  loss_data['val_loss'].append(val_loss/steps_per_epoch_val)\n",
        "  print('Epoch {} Loss {:.4f} val_los {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch, val_loss/steps_per_epoch_val))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 5.1018\n",
            "Epoch 1 Batch 100 Loss 3.1777\n",
            "Epoch 1 Batch 200 Loss 2.8989\n",
            "Epoch 1 Batch 300 Loss 2.6684\n",
            "Epoch 1 Batch 400 Loss 2.6512\n",
            "Epoch 1 Batch 500 Loss 2.5529\n",
            "Epoch 1 Batch 600 Loss 2.5056\n",
            "Epoch 1 Batch 700 Loss 2.4396\n",
            "Epoch 1 Loss 2.7507 val_los 2.5252\n",
            "Time taken for 1 epoch 254.85003399848938 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.3805\n",
            "Epoch 2 Batch 100 Loss 2.3378\n",
            "Epoch 2 Batch 200 Loss 2.2864\n",
            "Epoch 2 Batch 300 Loss 2.2049\n",
            "Epoch 2 Batch 400 Loss 2.1467\n",
            "Epoch 2 Batch 500 Loss 2.1666\n",
            "Epoch 2 Batch 600 Loss 2.1262\n",
            "Epoch 2 Batch 700 Loss 2.2710\n",
            "Epoch 2 Loss 2.2467 val_los 2.3130\n",
            "Time taken for 1 epoch 235.99372506141663 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.9806\n",
            "Epoch 3 Batch 100 Loss 1.9107\n",
            "Epoch 3 Batch 200 Loss 1.9644\n",
            "Epoch 3 Batch 300 Loss 1.9536\n",
            "Epoch 3 Batch 400 Loss 1.9933\n",
            "Epoch 3 Batch 500 Loss 1.8382\n",
            "Epoch 3 Batch 600 Loss 2.0105\n",
            "Epoch 3 Batch 700 Loss 2.0060\n",
            "Epoch 3 Loss 1.9590 val_los 2.1495\n",
            "Time taken for 1 epoch 233.46200275421143 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.7114\n",
            "Epoch 4 Batch 100 Loss 1.6796\n",
            "Epoch 4 Batch 200 Loss 1.7670\n",
            "Epoch 4 Batch 300 Loss 1.6722\n",
            "Epoch 4 Batch 400 Loss 1.6955\n",
            "Epoch 4 Batch 500 Loss 1.7429\n",
            "Epoch 4 Batch 600 Loss 1.8631\n",
            "Epoch 4 Batch 700 Loss 1.6982\n",
            "Epoch 4 Loss 1.7029 val_los 2.0336\n",
            "Time taken for 1 epoch 234.45417523384094 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.5100\n",
            "Epoch 5 Batch 100 Loss 1.3852\n",
            "Epoch 5 Batch 200 Loss 1.5504\n",
            "Epoch 5 Batch 300 Loss 1.5423\n",
            "Epoch 5 Batch 400 Loss 1.3889\n",
            "Epoch 5 Batch 500 Loss 1.4248\n",
            "Epoch 5 Batch 600 Loss 1.4759\n",
            "Epoch 5 Batch 700 Loss 1.4561\n",
            "Epoch 5 Loss 1.4662 val_los 1.9613\n",
            "Time taken for 1 epoch 232.41504836082458 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.2971\n",
            "Epoch 6 Batch 100 Loss 1.1377\n",
            "Epoch 6 Batch 200 Loss 1.2019\n",
            "Epoch 6 Batch 300 Loss 1.2408\n",
            "Epoch 6 Batch 400 Loss 1.2984\n",
            "Epoch 6 Batch 500 Loss 1.2581\n",
            "Epoch 6 Batch 600 Loss 1.1816\n",
            "Epoch 6 Batch 700 Loss 1.4191\n",
            "Epoch 6 Loss 1.2469 val_los 1.9333\n",
            "Time taken for 1 epoch 233.6429841518402 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.0110\n",
            "Epoch 7 Batch 100 Loss 0.9979\n",
            "Epoch 7 Batch 200 Loss 1.0979\n",
            "Epoch 7 Batch 300 Loss 0.9883\n",
            "Epoch 7 Batch 400 Loss 1.0680\n",
            "Epoch 7 Batch 500 Loss 1.0739\n",
            "Epoch 7 Batch 600 Loss 1.1278\n",
            "Epoch 7 Batch 700 Loss 1.0872\n",
            "Epoch 7 Loss 1.0476 val_los 1.9356\n",
            "Time taken for 1 epoch 232.2734363079071 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.7477\n",
            "Epoch 8 Batch 100 Loss 0.8116\n",
            "Epoch 8 Batch 200 Loss 0.7748\n",
            "Epoch 8 Batch 300 Loss 0.8725\n",
            "Epoch 8 Batch 400 Loss 0.8358\n",
            "Epoch 8 Batch 500 Loss 0.9050\n",
            "Epoch 8 Batch 600 Loss 0.9632\n",
            "Epoch 8 Batch 700 Loss 0.8486\n",
            "Epoch 8 Loss 0.8757 val_los 1.9607\n",
            "Time taken for 1 epoch 234.0060887336731 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.6428\n",
            "Epoch 9 Batch 100 Loss 0.6999\n",
            "Epoch 9 Batch 200 Loss 0.6826\n",
            "Epoch 9 Batch 300 Loss 0.7842\n",
            "Epoch 9 Batch 400 Loss 0.7662\n",
            "Epoch 9 Batch 500 Loss 0.7684\n",
            "Epoch 9 Batch 600 Loss 0.7809\n",
            "Epoch 9 Batch 700 Loss 0.7231\n",
            "Epoch 9 Loss 0.7318 val_los 2.0125\n",
            "Time taken for 1 epoch 231.8712456226349 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.6319\n",
            "Epoch 10 Batch 100 Loss 0.5631\n",
            "Epoch 10 Batch 200 Loss 0.5255\n",
            "Epoch 10 Batch 300 Loss 0.6357\n",
            "Epoch 10 Batch 400 Loss 0.5977\n",
            "Epoch 10 Batch 500 Loss 0.6862\n",
            "Epoch 10 Batch 600 Loss 0.6976\n",
            "Epoch 10 Batch 700 Loss 0.5642\n",
            "Epoch 10 Loss 0.6080 val_los 2.0588\n",
            "Time taken for 1 epoch 233.10013484954834 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxucQn9Uw2EP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "820bd7a0-b701-431c-e99b-0c19ca048fa8"
      },
      "source": [
        "import pickle\n",
        "with open('/gdrive/My Drive/강의자료/seq2seq_mecab(정방향)/loss_data.pickle','wb') as f:\n",
        "    pickle.dump(loss_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print('loss_data 저장 완료')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_data 저장 완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdUHKPZYxRSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7fa75fe4-3a9b-4a81-ee61-9862d3fceb6e"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(loss_data)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df['loss'], label= 'loss')\n",
        "plt.plot(df['val_loss'], label= 'val_loss')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tSAOrv4zs2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentences_kor(sentence)[0]\n",
        "  inputs = inp_lang.texts_to_sequences([sentence])[0]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "\n",
        "\n",
        "    # the predicted ID is fed back into the mode\n",
        "\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ggdBQ1zsbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBSGJsCpzxur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-TQmPAqhLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d43775fa-c926-4b92-f5bf-55035322a479"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa7fbd6d550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1mDFK7Gz0Ur",
        "colab_type": "text"
      },
      "source": [
        "## BLUE SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd9e17YKzand",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8449db5-aba3-4689-e3ba-925d3898e806"
      },
      "source": [
        "a,_,_ = evaluate([test_kor.values[3]])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i listened to music music in my house. <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNQbCl7J-Nlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6cbc4b27-238b-4120-f86e-0187e5993f9d"
      },
      "source": [
        "test_kor.values[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'이 프로그램은 준비하기 위한 과정으로 좋은 출발점이 될 것이에요.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quIU4Bl5762B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "a6890f7b-9444-47ea-fffa-222e9a0304b0"
      },
      "source": [
        "word_tokenize(test_en.values[i])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Because',\n",
              " 'of',\n",
              " 'studying',\n",
              " 'in',\n",
              " 'Brazil',\n",
              " ',',\n",
              " 'I',\n",
              " 'have',\n",
              " 'not',\n",
              " 'enough',\n",
              " 'money',\n",
              " 'now',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXPGK3PE3IqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7629acdd-a464-4f29-a02b-d140029f34ad"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "score_list = []\n",
        "smoothie = SmoothingFunction().method4\n",
        "for i in range(len(test_kor.values)):\n",
        "    \n",
        "    reference = [word_tokenize(test_en.values[i].lower())]\n",
        "    result,_,_= evaluate([test_kor.values[i]])\n",
        "    candidate = result.split()\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    score_list.append(score)\n",
        "    if i<20:\n",
        "        print('-'*20)\n",
        "        print('input : {}'.format(test_kor.values[i]))\n",
        "        print('실제값 : {}\\n예측값 : {}'.format(' '.join(reference[0]), ' '.join(candidate)))\n",
        "\n",
        "score = sum(score_list)/len(score_list)\n",
        "print('score는 {}'.format(score))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "input : 저는 오늘 그 이유에 대해 말하고자해요.\n",
            "실제값 : and i 'm here to explain the reason for this .\n",
            "예측값 : today , i want to talk about what that time .\n",
            "--------------------\n",
            "input : 오늘 저는 성형수술의 위험성에 대해 말하고자해요.\n",
            "실제값 : i want to say about the cosmetic sergery today .\n",
            "예측값 : today , i would like to tell you about the meaning of the public .\n",
            "--------------------\n",
            "input : 상기와 같은 조건으로 재계약을 하고자해요.\n",
            "실제값 : we would like to renew the contract in the condition above .\n",
            "예측값 : we will make a contract with the same as below .\n",
            "--------------------\n",
            "input : 우리의 방학이 다음주에 시작 돼.\n",
            "실제값 : our summer vacation starts next week .\n",
            "예측값 : our vacation will arrive next week .\n",
            "--------------------\n",
            "input : 그녀는 새로운 것을 창조해 내는 재밌는 작가야.\n",
            "실제값 : she is an interesting writer who creates new things .\n",
            "예측값 : she is a fun of perfume and good .\n",
            "--------------------\n",
            "input : 비오는 계절이 끝나자마자 시작돼요.\n",
            "실제값 : it begins soon after the rainy season is over .\n",
            "예측값 : it will be adjusted after the season will be held .\n",
            "--------------------\n",
            "input : 그리고 주문한 상품중 탑세개가 사이즈가 작아요.\n",
            "실제값 : plus , three tops i ordered do n't fit me ; they 're small .\n",
            "예측값 : and three sets and three different product is the sizes noted .\n",
            "--------------------\n",
            "input : 학교가 회사에 나를 추천하면 그 때부터 시작이야.\n",
            "실제값 : it will begin when the school recommends me to the company .\n",
            "예측값 : after school , it is expected from him from school , the school will be over until the school is the\n",
            "--------------------\n",
            "input : 참치가 지금 제철이니까 그걸로 시작하죠.\n",
            "실제값 : since tuna is in season now , let 's start with that .\n",
            "예측값 : it 's monthly go ahead and so it 's faded in korea .\n",
            "--------------------\n",
            "input : 왜 자꾸 일을 미룰까 생각 하지 말고 일을 시작해라.\n",
            "실제값 : begin to work , not thinking of putting off it .\n",
            "예측값 : do n't think about work in the matter .\n",
            "--------------------\n",
            "input : 일을 세부적으로 나누어 시작해라.\n",
            "실제값 : split the work in detail before you start .\n",
            "예측값 : refer to do it as a work .\n",
            "--------------------\n",
            "input : 그리고 서서히 사랑의 진실에 대해 눈뜨기 시작해요.\n",
            "실제값 : and they gradually started to realize the truth of love .\n",
            "예측값 : and it is supposed to feel the truth of love with love .\n",
            "--------------------\n",
            "input : 그러면서 두형제는 서로 갈등하기 시작해요.\n",
            "실제값 : then the brothers get into a conflict .\n",
            "예측값 : so the sky started to be adults .\n",
            "--------------------\n",
            "input : 한국에서는 혈액형으로 성격을 짐작해요.\n",
            "실제값 : people guess your personality by blood type in korea .\n",
            "예측값 : in korea , we can understand the freedom in korea .\n",
            "--------------------\n",
            "input : 나는 출근 해서 오늘 업무를 시작해요.\n",
            "실제값 : i came to work and started doing today 's work .\n",
            "예측값 : i will work for the work work and work .\n",
            "--------------------\n",
            "input : 회사에 도착해서 모닝 커피를 마시고 일과를 시작해요.\n",
            "실제값 : i arrived at the company and drank morning coffee .\n",
            "예측값 : i will take the coffee and i will change and butterfly assistant and decided to get a circle and worship form\n",
            "--------------------\n",
            "input : 친구 들과 함께 필리핀 북쪽 여행을 시작해요.\n",
            "실제값 : begin our travel nothern phillippines trip .\n",
            "예측값 : my lecture , i start to the philippines and sunday .\n",
            "--------------------\n",
            "input : 그는 전과 함께 사건의 범인을 추적하기 시작해요.\n",
            "실제값 : he starts to chase the criminal with jeon .\n",
            "예측값 : he will start the perspectives of the previous hospital .\n",
            "--------------------\n",
            "input : 무섭고 이상한 일이 일어나기 시작해요.\n",
            "실제값 : something scary and weird starts to happen .\n",
            "예측값 : sometimes it 's supposed to get worse .\n",
            "--------------------\n",
            "input : 그녀만을 위한 구두를 디자인하기 시작해요.\n",
            "실제값 : he begins to design a shoe just for her .\n",
            "예측값 : it is suggested to design the shoes for her .\n",
            "score는 0.2298619040251324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khtI17kcIyJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "88916597-5c34-43c3-fa35-0897daefe794"
      },
      "source": [
        "!pip install --upgrade bleu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bleu\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/df/4fd9bfe6dc240a1760f8e95ca41aa31382e328e31de45145f528dab5c7f8/bleu-0.3.tar.gz\n",
            "Collecting efficiency\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/9b/805e6da20cafbce2e2d08d92dce075d5cbb6316ecd473f4fe4f6373fb580/efficiency-0.4.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: spacy in /usr/local/lib/python3.6/dist-packages (from efficiency->bleu) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (3.1.0)\n",
            "Building wheels for collected packages: bleu, efficiency\n",
            "  Building wheel for bleu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bleu: filename=bleu-0.3-cp36-none-any.whl size=5801 sha256=1604ea6611d58cfb40100b53b9e3f2938525b66e930e2e498bdd3b93433beae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/95/e7/cb43a1c509c38fedbee6223963e34a51a94d8991f3b3e1888e\n",
            "  Building wheel for efficiency (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficiency: filename=efficiency-0.4-cp36-none-any.whl size=19617 sha256=f3c8cddc3664ab6b7ebf0498ddae77b9b42c85cf38662bc9f071c3b905532710\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/67/60/11693f94754d75dabfadb120c7ba380e7ef2aed8d3dccd00bf\n",
            "Successfully built bleu efficiency\n",
            "Installing collected packages: efficiency, bleu\n",
            "Successfully installed bleu-0.3 efficiency-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saExsHAWI2Z3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "e54597e9-0e6c-479b-e01e-dc3957ca12ea"
      },
      "source": [
        "pip install --upgrade git+git://github.com/zhijing-jin/bleu.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/zhijing-jin/bleu.git\n",
            "  Cloning git://github.com/zhijing-jin/bleu.git to /tmp/pip-req-build-awncxr3a\n",
            "  Running command git clone -q git://github.com/zhijing-jin/bleu.git /tmp/pip-req-build-awncxr3a\n",
            "Requirement already satisfied, skipping upgrade: efficiency in /usr/local/lib/python3.6/dist-packages (from bleu==0.3) (0.4)\n",
            "Requirement already satisfied, skipping upgrade: spacy in /usr/local/lib/python3.6/dist-packages (from efficiency->bleu==0.3) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu==0.3) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu==0.3) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu==0.3) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu==0.3) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu==0.3) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu==0.3) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu==0.3) (3.1.0)\n",
            "Building wheels for collected packages: bleu\n",
            "  Building wheel for bleu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bleu: filename=bleu-0.3-cp36-none-any.whl size=6773 sha256=6dbb68b02b5867dfec68baddb51a78b12e24919d464df591e7af56300ae4c351\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wl3pk52v/wheels/2b/79/93/d67db42308d30f8f11610565063bbf30c0f1ce08a23dfb95d8\n",
            "Successfully built bleu\n",
            "Installing collected packages: bleu\n",
            "  Found existing installation: bleu 0.3\n",
            "    Uninstalling bleu-0.3:\n",
            "      Successfully uninstalled bleu-0.3\n",
            "Successfully installed bleu-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lRJZvX4JVKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32c2d13c-b892-4a50-f8f0-1d451d6837fb"
      },
      "source": [
        "result,_,_ = evaluate([test_kor.values[1]])\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this program will be a good result for the stage. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMnjfqW2JRoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2192ab45-6d17-4a82-aa73-b9841bbba0b9"
      },
      "source": [
        "from bleu import list_bleu\n",
        "ref = ['wow , this dog is huge .']\n",
        "ref1 = ['This cat is white .',\n",
        "             'wow , this is a huge dog .']\n",
        "hyp = ['wowww , the dog is huge !']\n",
        "hyp1 = [\"it 's a white kitten .\",\n",
        "             'wow , this dog is huge !']\n",
        "list_bleu([ref], hyp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9cAqquILlqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "829dfc06-ea3f-44f8-8ef7-59c74172cbd8"
      },
      "source": [
        "test_kor.values[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['그것을 우리가 미리 확인하고 준비할 수 있을까요?',\n",
              "       '이 프로그램은 준비하기 위한 과정으로 좋은 출발점이 될 것이에요.',\n",
              "       '오늘 내가 인터넷으로 주문한 컴퓨터가 도착했어요.', '우리집에서 클래식 음악을 들었어.',\n",
              "       '사실대로 말하면, 저도 거기에서 왔어요.', '남녀 공학인 학교가 일반화되고 있어요.',\n",
              "       '이름에 학번을 넣는 것을 잊어 버렸어요.', '운동신경이 좋아 모든 운동을잘해요.',\n",
              "       '우리 애 들은 교회 수련회 갔어.', '국내를 선호하는 사람은 손을 들어주세요.'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOjVM6eiMZZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_sentence = []\n",
        "for i in test_kor.values[:300]:\n",
        "    a,_,_= evaluate([i])\n",
        "    predicted_sentence.append(a.capitalize())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xleYNri4I8SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d6e922fa-113d-4dc0-8a74-9f7a2d8bf710"
      },
      "source": [
        "from bleu import list_bleu\n",
        "print(test_en.values[0], predicted_sentence[0])\n",
        "score = list_bleu([test_en.values[:300]], predicted_sentence[:300])\n",
        "print(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could we check in advance and prepare that? Could we check our check and check out this coupon? \n",
            "7.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5jhnUt_cxbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trans(lang, sentences):\n",
        "    result_list=[]\n",
        "    for line in sentences:\n",
        "        result = ''\n",
        "        for idx in line:\n",
        "            if idx==1:continue\n",
        "            result += lang.index_word[idx] + ' '\n",
        "            if lang.index_word[idx] == '<end>':\n",
        "                result_list.append(result)\n",
        "                break\n",
        "\n",
        "        \n",
        "    return result_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSnGuFRTd0KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = trans(targ_lang, target_tensor_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu5_CirgyS9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = trans(inp_lang, input_tensor_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}