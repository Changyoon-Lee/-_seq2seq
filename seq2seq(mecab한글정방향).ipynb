{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq(mecab한글정방향).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Changyoon-Lee/realization_seq2seq/blob/master/seq2seq(mecab%ED%95%9C%EA%B8%80%EC%A0%95%EB%B0%A9%ED%96%A5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K30P_fc6q4j-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install python3-dev; pip3 install konlpy   # Python 3.x\n",
        "!sudo apt-get install curl\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv-nGWB3aeXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5cNaBHybT0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "news_df = pd.read_excel('/gdrive/My Drive/강의자료/kor.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "train_df, val_df, test_df = news_df.iloc[:50000, 1:], news_df.iloc[50000:63000, 1:], news_df.iloc[63000:, 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXus8NdNb73Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def preprocess_sentences_eng(sentences):\n",
        "    sentence = []\n",
        "    for line in sentences:\n",
        "        tokens = word_tokenize(line)\n",
        "        tokens.insert(0,'<start>')\n",
        "        tokens.append('<end>')\n",
        "        sentence.append(' '.join(tokens))\n",
        "    return sentence\n",
        "def preprocess_sentences_kor(sentences):\n",
        "    mecab = Mecab()\n",
        "    sentence = []\n",
        "    for line in sentences:\n",
        "        tokens = mecab.morphs(line)\n",
        "        tokens.insert(0,'<end>')\n",
        "        tokens.append('<start>')\n",
        "        sentence.append(' '.join(tokens[::-1]))\n",
        "    return sentence\n",
        "\n",
        "def backprocess_sentence(sentence):\n",
        "    tokens = sentence.split()\n",
        "    tokens = tokens[1:-1]\n",
        "    return ' '.join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sioFo_BLsKde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='', oov_token='oov')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBaRNUxqgs81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_en, test_en, val_en, train_kor, test_kor, val_kor = train_df['en'], test_df['en'], val_df['en'], train_df['ko'], test_df['ko'], val_df['ko']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVHKapVIvVle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_en = preprocess_sentences_eng(train_en)\n",
        "train_kor = preprocess_sentences_kor(train_kor)\n",
        "val_en = preprocess_sentences_eng(val_en)\n",
        "val_kor = preprocess_sentences_kor(val_kor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwoQt-NAuIEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_set 들로 tokenizer에 fit 시킨다\n",
        "input_tensor_train, inp_lang = tokenize(train_kor)\n",
        "target_tensor_train, targ_lang = tokenize(train_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIKfzXNfwChu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c3bf9122-bdf9-4838-a2d0-2a09f5ffbe99"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor_train.shape[1], input_tensor_train.shape[1]\n",
        "print('kor vocab size : {}\\nen vocab size : {}'.format(len(inp_lang.word_index), len(targ_lang.word_index)))\n",
        "print('kor_sentence_maxlen : {}\\nen_sentence_maxlen : {}'.format(max_length_inp, max_length_targ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kor vocab size : 17827\n",
            "en vocab size : 15640\n",
            "kor_sentence_maxlen : 32\n",
            "en_sentence_maxlen : 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQDndHCyh7Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_test(sent,lang='en'):\n",
        "    if lang=='ko':\n",
        "        tensor = inp_lang.texts_to_sequences(sent)\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen = max_length_inp,\n",
        "                                                         padding='post')\n",
        "        return tensor\n",
        "    else :\n",
        "        tensor = targ_lang.texts_to_sequences(sent)\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen =max_length_targ,\n",
        "                                                         padding='post')\n",
        "        return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q2EPlCJyQSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor_val = tokenize_test(val_kor, lang='ko')\n",
        "target_tensor_val = tokenize_test(val_en, lang='en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoTj9yiTwUrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "50baefe0-2fd0-4ffd-ce2e-96c50cd4d1ff"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 ----> <start>\n",
            "5 ----> i\n",
            "47 ----> go\n",
            "7 ----> to\n",
            "6 ----> the\n",
            "6439 ----> attic\n",
            "225 ----> every\n",
            "584 ----> evening\n",
            "7 ----> to\n",
            "148 ----> meet\n",
            "8459 ----> bat\n",
            "4 ----> .\n",
            "3 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hAyyyRkxw9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "#validation set 나누기\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_thX5ObOxxfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cb33e7f-3118-4700-e8af-6e6f24f9c6d3"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 32]), TensorShape([64, 21]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDWD3W71xxdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.random.uniform(shape=(self.batch_sz, self.enc_units), minval=-0.08, maxval=0.08)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JlgiYGMzfXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3d0a7f9-b388-4e49-d649-c2559c71dff7"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 32, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM0sHV-1ze8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGu1Dh8Gzex-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1bec09f9-1c65-4a98-c435-94f03a82bae1"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ubfXA-zjGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA6xP2Xpzjjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f6806bf-f89b-4b6a-c622-8dc41f9eb930"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 15641)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo98Sj63zi-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oqP_veazp59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/gdrive/My Drive/강의자료/seq2seq_mecab(정방향)'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIgGAjpgzpw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "def test_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        " \n",
        "  enc_out, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47tpoLZEzsjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b86b4ca1-faf6-4ef2-d966-e7d1f43336e7"
      },
      "source": [
        "EPOCHS = 10\n",
        "loss_data = {'loss':[],'val_loss':[]}\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  for inp, targ in val_dataset.take(steps_per_epoch_val):\n",
        "    batch_val_loss = test_step(inp, targ, enc_hidden)\n",
        "    val_loss += batch_val_loss\n",
        "  \n",
        "\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  loss_data['loss'].append(total_loss / steps_per_epoch)\n",
        "  loss_data['val_loss'].append(val_loss/steps_per_epoch_val)\n",
        "  print('Epoch {} Loss {:.4f} val_los {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch, val_loss/steps_per_epoch_val))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 5.1018\n",
            "Epoch 1 Batch 100 Loss 3.1777\n",
            "Epoch 1 Batch 200 Loss 2.8989\n",
            "Epoch 1 Batch 300 Loss 2.6684\n",
            "Epoch 1 Batch 400 Loss 2.6512\n",
            "Epoch 1 Batch 500 Loss 2.5529\n",
            "Epoch 1 Batch 600 Loss 2.5056\n",
            "Epoch 1 Batch 700 Loss 2.4396\n",
            "Epoch 1 Loss 2.7507 val_los 2.5252\n",
            "Time taken for 1 epoch 254.85003399848938 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.3805\n",
            "Epoch 2 Batch 100 Loss 2.3378\n",
            "Epoch 2 Batch 200 Loss 2.2864\n",
            "Epoch 2 Batch 300 Loss 2.2049\n",
            "Epoch 2 Batch 400 Loss 2.1467\n",
            "Epoch 2 Batch 500 Loss 2.1666\n",
            "Epoch 2 Batch 600 Loss 2.1262\n",
            "Epoch 2 Batch 700 Loss 2.2710\n",
            "Epoch 2 Loss 2.2467 val_los 2.3130\n",
            "Time taken for 1 epoch 235.99372506141663 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.9806\n",
            "Epoch 3 Batch 100 Loss 1.9107\n",
            "Epoch 3 Batch 200 Loss 1.9644\n",
            "Epoch 3 Batch 300 Loss 1.9536\n",
            "Epoch 3 Batch 400 Loss 1.9933\n",
            "Epoch 3 Batch 500 Loss 1.8382\n",
            "Epoch 3 Batch 600 Loss 2.0105\n",
            "Epoch 3 Batch 700 Loss 2.0060\n",
            "Epoch 3 Loss 1.9590 val_los 2.1495\n",
            "Time taken for 1 epoch 233.46200275421143 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.7114\n",
            "Epoch 4 Batch 100 Loss 1.6796\n",
            "Epoch 4 Batch 200 Loss 1.7670\n",
            "Epoch 4 Batch 300 Loss 1.6722\n",
            "Epoch 4 Batch 400 Loss 1.6955\n",
            "Epoch 4 Batch 500 Loss 1.7429\n",
            "Epoch 4 Batch 600 Loss 1.8631\n",
            "Epoch 4 Batch 700 Loss 1.6982\n",
            "Epoch 4 Loss 1.7029 val_los 2.0336\n",
            "Time taken for 1 epoch 234.45417523384094 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.5100\n",
            "Epoch 5 Batch 100 Loss 1.3852\n",
            "Epoch 5 Batch 200 Loss 1.5504\n",
            "Epoch 5 Batch 300 Loss 1.5423\n",
            "Epoch 5 Batch 400 Loss 1.3889\n",
            "Epoch 5 Batch 500 Loss 1.4248\n",
            "Epoch 5 Batch 600 Loss 1.4759\n",
            "Epoch 5 Batch 700 Loss 1.4561\n",
            "Epoch 5 Loss 1.4662 val_los 1.9613\n",
            "Time taken for 1 epoch 232.41504836082458 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.2971\n",
            "Epoch 6 Batch 100 Loss 1.1377\n",
            "Epoch 6 Batch 200 Loss 1.2019\n",
            "Epoch 6 Batch 300 Loss 1.2408\n",
            "Epoch 6 Batch 400 Loss 1.2984\n",
            "Epoch 6 Batch 500 Loss 1.2581\n",
            "Epoch 6 Batch 600 Loss 1.1816\n",
            "Epoch 6 Batch 700 Loss 1.4191\n",
            "Epoch 6 Loss 1.2469 val_los 1.9333\n",
            "Time taken for 1 epoch 233.6429841518402 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.0110\n",
            "Epoch 7 Batch 100 Loss 0.9979\n",
            "Epoch 7 Batch 200 Loss 1.0979\n",
            "Epoch 7 Batch 300 Loss 0.9883\n",
            "Epoch 7 Batch 400 Loss 1.0680\n",
            "Epoch 7 Batch 500 Loss 1.0739\n",
            "Epoch 7 Batch 600 Loss 1.1278\n",
            "Epoch 7 Batch 700 Loss 1.0872\n",
            "Epoch 7 Loss 1.0476 val_los 1.9356\n",
            "Time taken for 1 epoch 232.2734363079071 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.7477\n",
            "Epoch 8 Batch 100 Loss 0.8116\n",
            "Epoch 8 Batch 200 Loss 0.7748\n",
            "Epoch 8 Batch 300 Loss 0.8725\n",
            "Epoch 8 Batch 400 Loss 0.8358\n",
            "Epoch 8 Batch 500 Loss 0.9050\n",
            "Epoch 8 Batch 600 Loss 0.9632\n",
            "Epoch 8 Batch 700 Loss 0.8486\n",
            "Epoch 8 Loss 0.8757 val_los 1.9607\n",
            "Time taken for 1 epoch 234.0060887336731 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.6428\n",
            "Epoch 9 Batch 100 Loss 0.6999\n",
            "Epoch 9 Batch 200 Loss 0.6826\n",
            "Epoch 9 Batch 300 Loss 0.7842\n",
            "Epoch 9 Batch 400 Loss 0.7662\n",
            "Epoch 9 Batch 500 Loss 0.7684\n",
            "Epoch 9 Batch 600 Loss 0.7809\n",
            "Epoch 9 Batch 700 Loss 0.7231\n",
            "Epoch 9 Loss 0.7318 val_los 2.0125\n",
            "Time taken for 1 epoch 231.8712456226349 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.6319\n",
            "Epoch 10 Batch 100 Loss 0.5631\n",
            "Epoch 10 Batch 200 Loss 0.5255\n",
            "Epoch 10 Batch 300 Loss 0.6357\n",
            "Epoch 10 Batch 400 Loss 0.5977\n",
            "Epoch 10 Batch 500 Loss 0.6862\n",
            "Epoch 10 Batch 600 Loss 0.6976\n",
            "Epoch 10 Batch 700 Loss 0.5642\n",
            "Epoch 10 Loss 0.6080 val_los 2.0588\n",
            "Time taken for 1 epoch 233.10013484954834 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxucQn9Uw2EP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "820bd7a0-b701-431c-e99b-0c19ca048fa8"
      },
      "source": [
        "import pickle\n",
        "with open('/gdrive/My Drive/강의자료/seq2seq_mecab(정방향)/loss_data.pickle','wb') as f:\n",
        "    pickle.dump(loss_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print('loss_data 저장 완료')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_data 저장 완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdUHKPZYxRSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7fa75fe4-3a9b-4a81-ee61-9862d3fceb6e"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(loss_data)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df['loss'], label= 'loss')\n",
        "plt.plot(df['val_loss'], label= 'val_loss')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tSAOrv4zs2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentences_kor(sentence)[0]\n",
        "  inputs = inp_lang.texts_to_sequences([sentence])[0]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "\n",
        "\n",
        "    # the predicted ID is fed back into the mode\n",
        "\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ggdBQ1zsbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBSGJsCpzxur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-TQmPAqhLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d43775fa-c926-4b92-f5bf-55035322a479"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa7fbd6d550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1mDFK7Gz0Ur",
        "colab_type": "text"
      },
      "source": [
        "## BLUE SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXPGK3PE3IqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7629acdd-a464-4f29-a02b-d140029f34ad"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "score_list = []\n",
        "smoothie = SmoothingFunction().method4\n",
        "for i in range(len(test_kor.values)):\n",
        "    \n",
        "    reference = [word_tokenize(test_en.values[i].lower())]\n",
        "    result,_,_= evaluate([test_kor.values[i]])\n",
        "    candidate = result.split()\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    score_list.append(score)\n",
        "    if i<20:\n",
        "        print('-'*20)\n",
        "        print('input : {}'.format(test_kor.values[i]))\n",
        "        print('실제값 : {}\\n예측값 : {}'.format(' '.join(reference[0]), ' '.join(candidate)))\n",
        "\n",
        "score = sum(score_list)/len(score_list)\n",
        "print('score는 {}'.format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "input : 저는 오늘 그 이유에 대해 말하고자해요.\n",
            "실제값 : and i 'm here to explain the reason for this .\n",
            "예측값 : today , i want to talk about what that time .\n",
            "--------------------\n",
            "input : 오늘 저는 성형수술의 위험성에 대해 말하고자해요.\n",
            "실제값 : i want to say about the cosmetic sergery today .\n",
            "예측값 : today , i would like to tell you about the meaning of the public .\n",
            "--------------------\n",
            "input : 상기와 같은 조건으로 재계약을 하고자해요.\n",
            "실제값 : we would like to renew the contract in the condition above .\n",
            "예측값 : we will make a contract with the same as below .\n",
            "--------------------\n",
            "input : 우리의 방학이 다음주에 시작 돼.\n",
            "실제값 : our summer vacation starts next week .\n",
            "예측값 : our vacation will arrive next week .\n",
            "--------------------\n",
            "input : 그녀는 새로운 것을 창조해 내는 재밌는 작가야.\n",
            "실제값 : she is an interesting writer who creates new things .\n",
            "예측값 : she is a fun of perfume and good .\n",
            "--------------------\n",
            "input : 비오는 계절이 끝나자마자 시작돼요.\n",
            "실제값 : it begins soon after the rainy season is over .\n",
            "예측값 : it will be adjusted after the season will be held .\n",
            "--------------------\n",
            "input : 그리고 주문한 상품중 탑세개가 사이즈가 작아요.\n",
            "실제값 : plus , three tops i ordered do n't fit me ; they 're small .\n",
            "예측값 : and three sets and three different product is the sizes noted .\n",
            "--------------------\n",
            "input : 학교가 회사에 나를 추천하면 그 때부터 시작이야.\n",
            "실제값 : it will begin when the school recommends me to the company .\n",
            "예측값 : after school , it is expected from him from school , the school will be over until the school is the\n",
            "--------------------\n",
            "input : 참치가 지금 제철이니까 그걸로 시작하죠.\n",
            "실제값 : since tuna is in season now , let 's start with that .\n",
            "예측값 : it 's monthly go ahead and so it 's faded in korea .\n",
            "--------------------\n",
            "input : 왜 자꾸 일을 미룰까 생각 하지 말고 일을 시작해라.\n",
            "실제값 : begin to work , not thinking of putting off it .\n",
            "예측값 : do n't think about work in the matter .\n",
            "--------------------\n",
            "input : 일을 세부적으로 나누어 시작해라.\n",
            "실제값 : split the work in detail before you start .\n",
            "예측값 : refer to do it as a work .\n",
            "--------------------\n",
            "input : 그리고 서서히 사랑의 진실에 대해 눈뜨기 시작해요.\n",
            "실제값 : and they gradually started to realize the truth of love .\n",
            "예측값 : and it is supposed to feel the truth of love with love .\n",
            "--------------------\n",
            "input : 그러면서 두형제는 서로 갈등하기 시작해요.\n",
            "실제값 : then the brothers get into a conflict .\n",
            "예측값 : so the sky started to be adults .\n",
            "--------------------\n",
            "input : 한국에서는 혈액형으로 성격을 짐작해요.\n",
            "실제값 : people guess your personality by blood type in korea .\n",
            "예측값 : in korea , we can understand the freedom in korea .\n",
            "--------------------\n",
            "input : 나는 출근 해서 오늘 업무를 시작해요.\n",
            "실제값 : i came to work and started doing today 's work .\n",
            "예측값 : i will work for the work work and work .\n",
            "--------------------\n",
            "input : 회사에 도착해서 모닝 커피를 마시고 일과를 시작해요.\n",
            "실제값 : i arrived at the company and drank morning coffee .\n",
            "예측값 : i will take the coffee and i will change and butterfly assistant and decided to get a circle and worship form\n",
            "--------------------\n",
            "input : 친구 들과 함께 필리핀 북쪽 여행을 시작해요.\n",
            "실제값 : begin our travel nothern phillippines trip .\n",
            "예측값 : my lecture , i start to the philippines and sunday .\n",
            "--------------------\n",
            "input : 그는 전과 함께 사건의 범인을 추적하기 시작해요.\n",
            "실제값 : he starts to chase the criminal with jeon .\n",
            "예측값 : he will start the perspectives of the previous hospital .\n",
            "--------------------\n",
            "input : 무섭고 이상한 일이 일어나기 시작해요.\n",
            "실제값 : something scary and weird starts to happen .\n",
            "예측값 : sometimes it 's supposed to get worse .\n",
            "--------------------\n",
            "input : 그녀만을 위한 구두를 디자인하기 시작해요.\n",
            "실제값 : he begins to design a shoe just for her .\n",
            "예측값 : it is suggested to design the shoes for her .\n",
            "score는 0.2298619040251324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khtI17kcIyJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saExsHAWI2Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade git+git://github.com/zhijing-jin/bleu.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOjVM6eiMZZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_sentence = []\n",
        "for i in test_kor.values[:300]:\n",
        "    a,_,_= evaluate([i])\n",
        "    predicted_sentence.append(a.capitalize())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xleYNri4I8SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d6e922fa-113d-4dc0-8a74-9f7a2d8bf710"
      },
      "source": [
        "from bleu import list_bleu\n",
        "print(test_en.values[0], predicted_sentence[0])\n",
        "score = list_bleu([test_en.values[:300]], predicted_sentence[:300])\n",
        "print(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could we check in advance and prepare that? Could we check our check and check out this coupon? \n",
            "7.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5jhnUt_cxbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trans(lang, sentences):\n",
        "    result_list=[]\n",
        "    for line in sentences:\n",
        "        result = ''\n",
        "        for idx in line:\n",
        "            if idx==1:continue\n",
        "            result += lang.index_word[idx] + ' '\n",
        "            if lang.index_word[idx] == '<end>':\n",
        "                result_list.append(result)\n",
        "                break\n",
        "\n",
        "        \n",
        "    return result_list"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}