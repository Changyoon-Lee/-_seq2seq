{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq(mecab_역방향).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Changyoon-Lee/realization_seq2seq/blob/master/seq2seq(mecab_%EC%97%AD%EB%B0%A9%ED%96%A5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K30P_fc6q4j-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install python3-dev; pip3 install konlpy   # Python 3.x\n",
        "!sudo apt-get install curl\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv-nGWB3aeXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5cNaBHybT0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "news_df = pd.read_excel('/gdrive/My Drive/강의자료/kor.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "train_df, val_df, test_df = news_df.iloc[:50000, 1:], news_df.iloc[50000:63000, 1:], news_df.iloc[63000:, 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXus8NdNb73Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def preprocess_sentences_eng(sentences):\n",
        "    sentence = []\n",
        "    for line in sentences:\n",
        "        tokens = word_tokenize(line)\n",
        "        tokens.insert(0,'<start>')\n",
        "        tokens.append('<end>')\n",
        "        sentence.append(' '.join(tokens))\n",
        "    return sentence\n",
        "def preprocess_sentences_kor(sentences):\n",
        "    mecab = Mecab()\n",
        "    sentence = []\n",
        "    for line in sentences:\n",
        "        tokens = mecab.morphs(line)\n",
        "        tokens.insert(0,'<end>')\n",
        "        tokens.append('<start>')\n",
        "        sentence.append(' '.join(tokens[::-1]))\n",
        "    return sentence\n",
        "\n",
        "def backprocess_sentence(sentence):\n",
        "    tokens = sentence.split()\n",
        "    tokens = tokens[1:-1]\n",
        "    return ' '.join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sioFo_BLsKde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='', oov_token='oov')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBaRNUxqgs81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_en, test_en, val_en, train_kor, test_kor, val_kor = train_df['en'], test_df['en'], val_df['en'], train_df['ko'], test_df['ko'], val_df['ko']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVHKapVIvVle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_en = preprocess_sentences_eng(train_en)\n",
        "train_kor = preprocess_sentences_kor(train_kor)\n",
        "val_en = preprocess_sentences_eng(val_en)\n",
        "val_kor = preprocess_sentences_kor(val_kor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwoQt-NAuIEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_set 들로 tokenizer에 fit 시킨다\n",
        "input_tensor_train, inp_lang = tokenize(train_kor)\n",
        "target_tensor_train, targ_lang = tokenize(train_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIKfzXNfwChu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ff083919-0a5a-487b-dec5-ec4204c788b5"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor_train.shape[1], input_tensor_train.shape[1]\n",
        "print('kor vocab size : {}\\nen vocab size : {}'.format(len(inp_lang.word_index), len(targ_lang.word_index)))\n",
        "print('kor_sentence_maxlen : {}\\nen_sentence_maxlen : {}'.format(max_length_inp, max_length_targ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kor vocab size : 17827\n",
            "en vocab size : 15640\n",
            "kor_sentence_maxlen : 32\n",
            "en_sentence_maxlen : 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQDndHCyh7Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_test(sent,lang='en'):\n",
        "    if lang=='ko':\n",
        "        tensor = inp_lang.texts_to_sequences(sent)\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen = max_length_inp,\n",
        "                                                         padding='post')\n",
        "        return tensor\n",
        "    else :\n",
        "        tensor = targ_lang.texts_to_sequences(sent)\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen =max_length_targ,\n",
        "                                                         padding='post')\n",
        "        return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q2EPlCJyQSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor_val = tokenize_test(val_kor, lang='ko')\n",
        "target_tensor_val = tokenize_test(val_en, lang='en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoTj9yiTwUrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "8b1c81e9-38ec-4d01-df2d-ee65563c3155"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 ----> <start>\n",
            "5 ----> i\n",
            "47 ----> go\n",
            "7 ----> to\n",
            "6 ----> the\n",
            "6439 ----> attic\n",
            "225 ----> every\n",
            "584 ----> evening\n",
            "7 ----> to\n",
            "148 ----> meet\n",
            "8459 ----> bat\n",
            "4 ----> .\n",
            "3 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hAyyyRkxw9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "#validation set 나누기\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_thX5ObOxxfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6280f290-c3f7-49d2-dcc9-435c981dccdd"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 32]), TensorShape([64, 21]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDWD3W71xxdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.random.uniform(shape=(self.batch_sz, self.enc_units), minval=-0.08, maxval=0.08)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JlgiYGMzfXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75151946-7b85-4241-9019-d7b57c97827e"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 32, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM0sHV-1ze8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGu1Dh8Gzex-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f8de415e-2d56-4c28-bd5f-1ac7a63240c6"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ubfXA-zjGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA6xP2Xpzjjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8afbcd05-138f-4e6c-b24b-a92360e71c17"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 15641)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo98Sj63zi-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oqP_veazp59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/gdrive/My Drive/강의자료/seq2seq_mecab'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIgGAjpgzpw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "def test_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        " \n",
        "  enc_out, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47tpoLZEzsjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10\n",
        "loss_data = {'loss':[],'val_loss':[]}\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  for inp, targ in val_dataset.take(steps_per_epoch_val):\n",
        "    batch_val_loss = test_step(inp, targ, enc_hidden)\n",
        "    val_loss += batch_val_loss\n",
        "  \n",
        "\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  loss_data['loss'].append(total_loss / steps_per_epoch)\n",
        "  loss_data['val_loss'].append(val_loss/steps_per_epoch_val)\n",
        "  print('Epoch {} Loss {:.4f} val_los {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch, val_loss/steps_per_epoch_val))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdUHKPZYxRSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5ad8279-7ed2-4719-e4e3-47639a3d9eea"
      },
      "source": [
        "import pickle\n",
        "with open('/gdrive/My Drive/강의자료/seq2seq_mecab/loss_data.pickle','wb') as f:\n",
        "    pickle.dump(loss_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print('loss_data 저장 완료')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_data 저장 완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tSAOrv4zs2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentences_kor(sentence)[0]\n",
        "  inputs = inp_lang.texts_to_sequences([sentence])[0]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "\n",
        "\n",
        "    # the predicted ID is fed back into the mode\n",
        "\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ggdBQ1zsbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBSGJsCpzxur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWgmbPwozxnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(['안녕'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-TQmPAqhLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ca79d74-4b6a-4540-fcc3-29235c65a000"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f06bb8636d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ZwA1xMdP42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0828e363-d1dc-4bcc-c050-275c5a8de17d"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(loss_data)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df['loss'], label= 'loss')\n",
        "plt.plot(df['val_loss'], label= 'val_loss')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1mDFK7Gz0Ur",
        "colab_type": "text"
      },
      "source": [
        "## BLUE SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXPGK3PE3IqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92fb26f5-5e05-4cb0-89f5-69c8b345a062"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "score_list = []\n",
        "smoothie = SmoothingFunction().method4\n",
        "for i in range(len(test_kor.values)):\n",
        "    \n",
        "    reference = [word_tokenize(test_en.values[i].lower())]\n",
        "    result,_,_= evaluate([test_kor.values[i]])\n",
        "    candidate = result.split()\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    score_list.append(score)\n",
        "    if i<20:\n",
        "        print('-'*20)\n",
        "        print('input : {}'.format(test_kor.values[i]))\n",
        "        print('실제값 : {}\\n예측값 : {}'.format(' '.join(reference[0]), ' '.join(candidate)))\n",
        "\n",
        "score = sum(score_list)/len(score_list)\n",
        "print('score는 {}'.format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "input : 저는 오늘 그 이유에 대해 말하고자해요.\n",
            "실제값 : and i 'm here to explain the reason for this .\n",
            "예측값 : today , i want to talk about that professor today .\n",
            "--------------------\n",
            "input : 오늘 저는 성형수술의 위험성에 대해 말하고자해요.\n",
            "실제값 : i want to say about the cosmetic sergery today .\n",
            "예측값 : today , i want to talk about the importance of the truth of the future .\n",
            "--------------------\n",
            "input : 상기와 같은 조건으로 재계약을 하고자해요.\n",
            "실제값 : we would like to renew the contract in the condition above .\n",
            "예측값 : i want to sign the contract with the above above .\n",
            "--------------------\n",
            "input : 우리의 방학이 다음주에 시작 돼.\n",
            "실제값 : our summer vacation starts next week .\n",
            "예측값 : our vacation begins for next week .\n",
            "--------------------\n",
            "input : 그녀는 새로운 것을 창조해 내는 재밌는 작가야.\n",
            "실제값 : she is an interesting writer who creates new things .\n",
            "예측값 : she is a fun that i can enjoy the new zealand .\n",
            "--------------------\n",
            "input : 비오는 계절이 끝나자마자 시작돼요.\n",
            "실제값 : it begins soon after the rainy season is over .\n",
            "예측값 : taeyeon is completed as the weather season .\n",
            "--------------------\n",
            "input : 그리고 주문한 상품중 탑세개가 사이즈가 작아요.\n",
            "실제값 : plus , three tops i ordered do n't fit me ; they 're small .\n",
            "예측값 : and the three products are three color is a size is the size is the size is the size is the\n",
            "--------------------\n",
            "input : 학교가 회사에 나를 추천하면 그 때부터 시작이야.\n",
            "실제값 : it will begin when the school recommends me to the company .\n",
            "예측값 : i am the first when i first when i first to school .\n",
            "--------------------\n",
            "input : 참치가 지금 제철이니까 그걸로 시작하죠.\n",
            "실제값 : since tuna is in season now , let 's start with that .\n",
            "예측값 : the distribution is determined because it is coming now .\n",
            "--------------------\n",
            "input : 왜 자꾸 일을 미룰까 생각 하지 말고 일을 시작해라.\n",
            "실제값 : begin to work , not thinking of putting off it .\n",
            "예측값 : why do n't think about delaying your work .\n",
            "--------------------\n",
            "input : 일을 세부적으로 나누어 시작해라.\n",
            "실제값 : split the work in detail before you start .\n",
            "예측값 : please make the things that we are doing .\n",
            "--------------------\n",
            "input : 그리고 서서히 사랑의 진실에 대해 눈뜨기 시작해요.\n",
            "실제값 : and they gradually started to realize the truth of love .\n",
            "예측값 : and it makes me about the truth of love .\n",
            "--------------------\n",
            "input : 그러면서 두형제는 서로 갈등하기 시작해요.\n",
            "실제값 : then the brothers get into a conflict .\n",
            "예측값 : in addition , the adults and creative and more .\n",
            "--------------------\n",
            "input : 한국에서는 혈액형으로 성격을 짐작해요.\n",
            "실제값 : people guess your personality by blood type in korea .\n",
            "예측값 : in the city , people can describe the sense of art .\n",
            "--------------------\n",
            "input : 나는 출근 해서 오늘 업무를 시작해요.\n",
            "실제값 : i came to work and started doing today 's work .\n",
            "예측값 : i start work work for work .\n",
            "--------------------\n",
            "input : 회사에 도착해서 모닝 커피를 마시고 일과를 시작해요.\n",
            "실제값 : i arrived at the company and drank morning coffee .\n",
            "예측값 : after welding and prepare a tea .\n",
            "--------------------\n",
            "input : 친구 들과 함께 필리핀 북쪽 여행을 시작해요.\n",
            "실제값 : begin our travel nothern phillippines trip .\n",
            "예측값 : i will travel to the philippines with my friends .\n",
            "--------------------\n",
            "input : 그는 전과 함께 사건의 범인을 추적하기 시작해요.\n",
            "실제값 : he starts to chase the criminal with jeon .\n",
            "예측값 : he needs to know the way of the ground .\n",
            "--------------------\n",
            "input : 무섭고 이상한 일이 일어나기 시작해요.\n",
            "실제값 : something scary and weird starts to happen .\n",
            "예측값 : i get payed much pain and mentally .\n",
            "--------------------\n",
            "input : 그녀만을 위한 구두를 디자인하기 시작해요.\n",
            "실제값 : he begins to design a shoe just for her .\n",
            "예측값 : we decided the food that we should wear clothes .\n",
            "score는 0.23257414327895823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjUzhTzoQsvX",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Moses' script for detokenized BLEU\n",
        "참고 : https://pypi.org/project/bleu/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khtI17kcIyJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saExsHAWI2Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade git+git://github.com/zhijing-jin/bleu.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMnjfqW2JRoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2192ab45-6d17-4a82-aa73-b9841bbba0b9"
      },
      "source": [
        "from bleu import list_bleu\n",
        "ref = ['wow , this dog is huge .']\n",
        "ref1 = ['This cat is white .',\n",
        "             'wow , this is a huge dog .']\n",
        "hyp = ['wowww , the dog is huge !']\n",
        "hyp1 = [\"it 's a white kitten .\",\n",
        "             'wow , this dog is huge !']\n",
        "list_bleu([ref], hyp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9cAqquILlqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "829dfc06-ea3f-44f8-8ef7-59c74172cbd8"
      },
      "source": [
        "test_kor.values[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['그것을 우리가 미리 확인하고 준비할 수 있을까요?',\n",
              "       '이 프로그램은 준비하기 위한 과정으로 좋은 출발점이 될 것이에요.',\n",
              "       '오늘 내가 인터넷으로 주문한 컴퓨터가 도착했어요.', '우리집에서 클래식 음악을 들었어.',\n",
              "       '사실대로 말하면, 저도 거기에서 왔어요.', '남녀 공학인 학교가 일반화되고 있어요.',\n",
              "       '이름에 학번을 넣는 것을 잊어 버렸어요.', '운동신경이 좋아 모든 운동을잘해요.',\n",
              "       '우리 애 들은 교회 수련회 갔어.', '국내를 선호하는 사람은 손을 들어주세요.'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOjVM6eiMZZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_sentence = []\n",
        "for i in test_kor.values[:300]:\n",
        "    a,_,_= evaluate([i])\n",
        "    predicted_sentence.append(a.capitalize())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xleYNri4I8SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d6e922fa-113d-4dc0-8a74-9f7a2d8bf710"
      },
      "source": [
        "from bleu import list_bleu\n",
        "print(test_en.values[0], predicted_sentence[0])\n",
        "score = list_bleu([test_en.values[:300]], predicted_sentence[:300])\n",
        "print(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could we check in advance and prepare that? Could we check our check and check out this coupon? \n",
            "7.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5jhnUt_cxbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trans(lang, sentences):\n",
        "    result_list=[]\n",
        "    for line in sentences:\n",
        "        result = ''\n",
        "        for idx in line:\n",
        "            if idx==1:continue\n",
        "            result += lang.index_word[idx] + ' '\n",
        "            if lang.index_word[idx] == '<end>':\n",
        "                result_list.append(result)\n",
        "                break\n",
        "\n",
        "        \n",
        "    return result_list"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}